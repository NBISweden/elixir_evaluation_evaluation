{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Improving the ELIXIR evaluation for both management and trainers","text":"<p>An evaluation of the ELIXIR course evaluation.</p> <ul> <li>Download the PDF of the draft paper</li> </ul>"},{"location":"#goals","title":"Goals","text":"<ul> <li>To evaluate the mandatory ELIXIR course evaluation questions   regarding course quality</li> </ul> What are these ELIXIR evaluation questions? <p>Read the ELIXIR evaluation questions.</p> <p>This paper deals only with the mandatory questions 5 to and including 9.</p> <ul> <li>If possible, propose a better set of questions</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>This evaluation is written as a scientific paper, split over multiple pages (for now):</p> <ul> <li>Authors: Rich\u00e8l Bilderbeek, Daniel Wibberg</li> <li>Abstract</li> <li>Introduction</li> <li>Research questions</li> <li>Methods:<ul> <li>RQ1 Methods</li> <li>RQ2 Methods</li> <li>RQ3 Methods</li> <li>RQ4 Methods</li> </ul> </li> <li>Results:<ul> <li>RQ1 Results</li> <li>RQ2 Results</li> <li>RQ3 Results</li> <li>RQ4 Results</li> </ul> </li> <li>Conclusion</li> <li>Discussion</li> <li>Appendix<ul> <li>The current ELIXIR short-term evaluation</li> </ul> </li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at marcus.lundberg@uppmax.uu.se. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Thanks for considering to contribute and reading this!</p> <p>Here we discuss how to contribute</p> <ul> <li>Spoken text, e.g. ideas, feedback, messages, etc.   and are written in English.</li> <li>Code, e.g. textual changes where the text is formatted in Markdown</li> </ul>"},{"location":"CONTRIBUTING/#spoken-text","title":"Spoken text","text":"<p>Spoken text are ideas, feedback, messages, etc. and are written in English.</p> <p>For ideas or feedback, create an Issue. These Issues will be discussed in a meeting and/or below that Issue.</p> <p>Ideas that improve the experience of our learners will likely be accepted.</p>"},{"location":"CONTRIBUTING/#code","title":"Code","text":"<p>We welcome any contribution that:</p> <ul> <li>improves the experience of our learners</li> <li>follow all standards set by the continuous integration tools   (e.g. use 4 spaces for indentation)</li> </ul> <p>As an UPPMAX contributor, one can contribute by:</p> <ol> <li>Clone this repository</li> <li>Add a branch</li> <li>Work on your branch</li> <li>When done, create a Pull Request from your branch to <code>main</code></li> <li>If the change is accepted after review it will be merged into the main branch</li> <li>Your branch will be deleted after merging</li> </ol> <p>As an external contributor, one can contribute by:</p> <ol> <li>Fork this repository</li> <li>Modify your Fork</li> <li>When done, creating a Pull Request from your Fork to this repository,    merging to the <code>main</code> branch is fine :-)</li> <li>If the change is accepted after review it will be merged into the main branch</li> </ol>"},{"location":"abstract/","title":"Abstract","text":"<p>NBIS teaches, among others, bioinformatics courses, which are evaluated with an anonymous survey sent its learners. Part of this survey consists of mandatory questions to assess course quality. However, there is discussion in how useful these questions are in achieving their goal. Here, we describe the history of this survey, how its questions were crafted and selected, followed by an evaluation of its final form. We find that no selection criterium has been written down and evidence-based best practices by the academic literature were ignored. This paper is the first to transparently show the crafting and selection of evaluation questions to be used for NBIS evaluation, being the 'future work' as mentioned in its paper most important to this topic.</p>"},{"location":"conclusion/","title":"5. Conclusion","text":""},{"location":"conclusion/#51-rq1-what-is-the-history-of-the-elixir-evaluation-questions","title":"5.1. RQ1: What is the history of the ELIXIR evaluation questions?","text":"<p>The ELIXIR student evaluation is based on two evaluations. Neither evaluation describes (1) how its questions were developed, (2) by which criteria the best questions were selected.</p> <p>From these two questionnaires, some (but not all) questions were selected to be put in the ELIXIR evaluation. Additionally, ELIXIR added new questions, regarding student satisfactions. The criteria for neither not copying questions for the earlier questionnaires, not for adding adding questions were not written down.</p> <p>As none of these evaluations describe the process on how questions were developed, it comes as no surprise that neither evaluation refers to evidence-based best practices in the literature.</p>"},{"location":"conclusion/#52-rq2-how-does-the-academic-literature-relate-to-the-elixir-evaluation-questions","title":"5.2. RQ2: How does the academic literature relate to the ELIXIR evaluation questions?","text":"<p>The mandatory ELIXIR evaluation questions with the goal of evaluating course quality have the following relation to the academic literature</p> Index Question Connection to the academic literature 5 Have you used the tools/resource(s) covered in the course before? None found 6 Will you use the tools/resource(s) covered in the course again? None found 7 Would you recommend the course? One paper which states that this question is suitable to assess course quality 8 What is your overall rating for the course? Many papers, including a meta-analysis that this question is unsuitable to assess course quality 9 May we contact you by email in the future for more feedback? None found"},{"location":"conclusion/#53-rq3-which-elixir-evaluation-questions-are-concluded-from-a-fully-transparent-process","title":"5.3. RQ3: Which ELIXIR evaluation questions are concluded from a fully transparent process?","text":"<p><code>TODO</code></p>"},{"location":"conclusion/#54-rq4-how-different-are-the-newly-suggested-questions-from-the-current-ones","title":"5.4. RQ4: How different are the newly suggested questions from the current ones?","text":"<p><code>TODO</code></p>"},{"location":"data_set_1_merge/","title":"Data set 1 merge","text":"<p>There were 5 questions.</p> <p>Of those 5, here are 2 questions with different spelling:</p> <pre><code>What is your favorite color?,Open question\nWhat is your favorite colour?,Open question\n</code></pre> <p>RJCB removed the one with <code>colour</code>, resulting in 4 questions.</p> <p>Of the remaining 4, here are 2 identical questions:</p> <pre><code>What is your favorite animal?,Open question\nWhat is your favorite animal?,Open question\n</code></pre> <p>RJCB removed one of these duplicates, resulting in 3 questions.</p>"},{"location":"discussion/","title":"6. Discussion","text":"<p>First and foremost, one can argue that a questionnaire is simply a questionnaire. That the development of a questionnaire is 'just' a group effort. That the people in such groups are constrained by time. And that this is a good enough excuse. However, this overlooks the fact that at least sixteen thousand participants have taken the time to fill in this questionnaire. If we care about our participants, maybe we should care about the usefulness of a questionnaire we send to each of them.</p>"},{"location":"discussion/#61-rq1-what-is-the-history-of-the-elixir-evaluation-questions","title":"6.1. RQ1: What is the history of the ELIXIR evaluation questions?","text":"<p>Although this is not formally published, maybe the current survey (or the surveys it is based on) have been developed by evidence-based best practices, yet in unpublished and more informal documents. However, it seems unlikely that references to the literature are used in informal communication, yet subsequently omitted when a formal academic paper is written.</p> <p>To us, it seems more likely that a too short amount of time was allocated to researching the academic literature, resulting in missing the papers mentioned in this paper.</p>"},{"location":"discussion/#62-rq2-how-does-the-academic-literature-relate-to-the-elixir-evaluation-questions","title":"6.2. RQ2: How does the academic literature relate to the ELIXIR evaluation questions?","text":"<p>The majority of the ELIXIR mandatory evaluation questions, in the section to assess course quality have little connection to the academic literature. Three out of five questions (i.e. questions 5, 6 and 9) resulted in zero papers being written on their effectiveness.</p> <p>To us, these questions simply seem to be in the wrong session. Why it was chosen to put these questions in the section called 'quality metrics', instead of a (new) section with a better fitting name is unknown.</p> <p>Regarding the two questions that seem to be in the correct section, however, only one is supported by the literature ('Would you recommend the course?') by one paper, where the other ('How satisfied are you with the course?') has strong support against its effectiveness.</p> <p>Regarding these two questions, they seem to be measuring the same thing: course satisfaction (on its own), and recommending a course (because the learner is satisfied with the course). It is unknown why these two similar questions are both in the evaluation and it would be interesting to see how strong the correlation is between the answers on these two questions.</p>"},{"location":"discussion/#63-epilogue","title":"6.3. Epilogue","text":"<p>We know that a teacher reflecting on his/her work is one of the best ways to increase his/her teaching quality. Or: 'student ratings can only become a tool for enhancement when they feed reflective conversations about improving the learning process and when these conversations are informed by the scholarship of teaching and learning <code>[Rox\u00e5 et al., 2021]</code>. The other best way for teachers to improve is to do peer observations. Note that neither practice needs an evaluations.</p> <p>If we really care about teaching quality, shouldn't we encourage doing the things that actually work?</p>"},{"location":"discussion/#64-references","title":"6.4. References","text":"<ul> <li><code>[Rox\u00e5 et al., 2021]</code> Rox\u00e5, Torgny, et al.   \"Reconceptualizing student ratings of teaching to support quality discourse   on student learning: a systems perspective.\" Higher Education (2021): 1-21.</li> </ul>"},{"location":"elixir_evaluation/","title":"A1. NBIS Short Term Feedback (STF)","text":"<pre><code>Besides this text, this page shows the current\nNBIS Short Term Feedback form. Except for changes in layout\nand the numbering of sections, \nthe content is unmodified.\n</code></pre>"},{"location":"elixir_evaluation/#a11core-question-set-information","title":"A1.1.Core question set information","text":"<p>The intention of the STF survey is to find out how participants have used the skills and knowledge they gained through participating in the NBIS course.</p> <p>The STF survey aims to provide data back to NBIS from course participants.</p> <p>The survey should preferably be given by the course leader to the participants on the last day of the course. Some of the questions below are CORE Questions and needs to always be included in the survey. There are also room for ADDITIONAL questions that can be modified for respective course.</p> <ul> <li>Contents</li> <li>Important Information</li> <li>Core Question Set</li> <li>Demographic Information</li> <li>Quality Metrics</li> <li>Additional Questions - Training content/information</li> <li>Additional Questions - Training logistics</li> </ul>"},{"location":"elixir_evaluation/#a12-important-information","title":"A1.2. Important Information","text":"<p>Below are the core questions for NBIS short term feedback (STF), which are required to be captured for all NBIS training events from August 2018 onwards, most typically in an end-of-training-event feedback survey (i.e. exit survey). The information and Core questions are extracted from the ELIXIR and ELIXIR-EXCELERATE courses. Additional questions are free to be modified to suit the course needs. The format for collecting the data is up to each training provider, although results should be exportable to Excel format. The core questions may be divided into two categories and will by and large be analysed separately - both categories are required to be captured:</p> <ul> <li>Demographic information</li> <li>Quality metrics</li> </ul> <p>For the demographic information questions specifically, these may be captured either in the exit survey OR in the registration form. The exit survey should be administered as close as possible to the end of the training event, preferably on the last day of the course. Please add the result of the survey to the course folder in Google Drive (NBIS Course Catalogue).</p> <p>The core question set is followed by a set of Additional (suggested) questions that training organisers might also like to ask. Please note: while the core question set is compulsory, Course leader(s) are encouraged to ask any additional questions for their own collection and data analysis, should they wish.</p> <p>Data formatting: Preferred column headers for each core metric are in \u2018red\u2019. It would be very helpful for analysing the data if everyone used these column headings when exporting the results. Please note: these descriptors are case sensitive (e.g. use <code>advertised</code> not <code>Advertised</code>). Also, the underscores are important! (e.g. <code>career_stage</code> is NOT the same as <code>career stage</code>).</p> <p>If possible, please name the dataset file as follows to assist with data handling: <code>YYYY-MM-DD_L/STF_Location_CourseName</code>, e.g. <code>2018-06-11_STF_Visby_RaukR</code></p>"},{"location":"elixir_evaluation/#a13-core-question-set","title":"A1.3. Core Question Set","text":""},{"location":"elixir_evaluation/#a14-section-1-template-nbis-short-term-feedback-stf-survey-course-name-location-yyyy-mm-dd","title":"A1.4. Section 1 - Template: NBIS Short Term Feedback (STF) survey <code>COURSE NAME, LOCATION, YYYY-MM-DD</code>","text":"<p>Thank you for filling the questionnaire. It is really important to us in order to continually improve the course and the materials we deliver. In filling the questionnaire, please keep in mind that your comments - which are not mandatory - are especially precious. We may share anonymised information with course presenters and developers as well as for wider quality/impact analyses.</p>"},{"location":"elixir_evaluation/#a15-section-2-demographic-information","title":"A1.5. Section 2 - Demographic Information","text":"<p><code>1</code>. Where did you see the course advertised? <code>advertised</code></p> <ul> <li><code>a</code>. NBIS website</li> <li><code>b</code>. SciLifeLab website</li> <li><code>c</code>. Social Media (e.g. NBIS twitter)</li> <li><code>d</code>. Host Institute website</li> <li><code>e</code>. Colleague</li> <li><code>f</code>. TeSS</li> <li><code>g</code>. Email</li> <li><code>h</code>. Internet search</li> <li><code>i</code>. Other (comments)</li> </ul> <p><code>2</code>. What is your career stage? <code>career_stage</code></p> <ul> <li><code>a</code>. PhD candidate</li> <li><code>b</code>. Postdoctoral researcher</li> <li><code>c</code>. Senior researcher/Principal investigator</li> <li><code>d</code>. Staff scientist</li> <li><code>e</code>. Industry scientist</li> <li><code>f</code>. Other (comments)</li> </ul> <p><code>3</code>. What is your host university? <code>host_university</code></p> <p><code>4</code>. Gender <code>gender</code></p> <ul> <li><code>a</code>. Male</li> <li><code>b</code>. Female</li> <li><code>c</code>. Prefer not to say</li> <li><code>d</code>. Other (please specify)</li> </ul>"},{"location":"elixir_evaluation/#a16-section-3-quality-metrics","title":"A1.6. Section 3 - Quality Metrics","text":"<p><code>5</code>. Have you used the tools/resource(s) covered in the course before? <code>have_used_resources_before</code></p> <ul> <li><code>1</code>. Never - Unaware of them</li> <li><code>2</code>. Never - Used other service</li> <li><code>3</code>. Occasionally</li> <li><code>4</code>. Frequently</li> </ul> <p><code>6</code>. Will you use the tools/resource(s) covered in the course again? <code>will_use_resources_future</code></p> <ul> <li><code>1</code>. Yes</li> <li><code>2</code>. No</li> <li><code>3</code>. Maybe</li> </ul> <p><code>7</code>. Would you recommend the course? <code>would_recommend_course</code></p> <ul> <li><code>1</code>. Yes</li> <li><code>2</code>. No</li> <li><code>3</code>. Maybe</li> </ul> <p><code>8</code>. What is your overall rating for the course*. <code>overall_satisfaction</code></p> <ul> <li><code>a</code>. Poor (1)</li> <li><code>b</code>. Satisfactory (2)</li> <li><code>c</code>. Good (3)</li> <li><code>d</code>. Very Good (4)</li> <li><code>e</code>. Excellent (5)</li> </ul> <p>(*please include both numeric and categorical scale for this question.)</p> <p><code>9</code>. A. May we contact you by email in the future for more feedback? <code>contact_future</code></p> <ul> <li><code>1</code>. Yes</li> <li><code>2</code>. No</li> </ul> <p>9 B. If you answered \u2018yes\u2019 to the above question, please enter your email address, below. email ( Information for question 9B must be collected and stored by each Node/Institution, but should NOT be shared with the Q&amp;I subtask or any other third party due to GDPR considerations.)</p>"},{"location":"elixir_evaluation/#a17-additional-questions-training-contentinformation","title":"A1.7. Additional Questions - Training content/information","text":"<p>These are suggested questions that may be of interest (not compulsory):</p> <p><code>1</code>. What part of the training did you enjoy the most? <code>enjoy</code></p> <p><code>2</code>. What part of the training did you enjoy the least? <code>to_improve</code></p> <p><code>3</code>. The balance of theoretical and practical content was <code>theoretical_practical</code></p> <ul> <li><code>a</code>. Too practical</li> <li><code>b</code>. About right</li> <li><code>c</code>. Too theoretical</li> </ul> <p><code>4</code>. How do you rate the pre-course information given? pre_course_information</p> <ul> <li>Linear scale 1-5</li> <li><code>1</code>. (Very unsatisfactory/Not useful)</li> <li><code>5</code>. Very good/Very useful</li> </ul> <p><code>5</code>. What other topics would you like to see covered in the future? <code>future_topics</code></p> <p><code>6</code>. Any other comments? Comments</p> <p><code>7</code>. PLEASE RATE EACH SESSION OF THE COURSE <code>satisfaction_per_session_YYYY_MM_DD_am/pm</code></p> <ul> <li><code>a</code>. Did not attend</li> <li><code>b</code>. Poor (1)</li> <li><code>c</code>. Satisfactory (2)</li> <li><code>d</code>. Good (3)</li> <li><code>e</code>. Very Good (4)</li> <li><code>f</code>. Excellent (5)</li> </ul> <p><code>8</code>. Comments on teaching staff <code>teaching_staff</code>     Help our teaching staff to improve by providing constructive feedback     Paragraph text answer</p> <p><code>9</code>. Was the course held at a teaching level matching your training? teaching_training_level</p> <p><code>10</code>. STATEMENTS REGARDING WHAT PARTICIPANTS COULD DO before TRAINING (customised to a specific training) skills_before</p> <p><code>11</code>. STATEMENTS REGARDING WHAT PARTICIPANTS CAN DO after TRAINING (customised to a specific training) skills_after</p> <p><code>12</code>. What other topics would you like to see covered in the future? future_topics</p> <p><code>13</code>. Any other comments? Comments_1</p>"},{"location":"elixir_evaluation/#a18-additional-questions-training-logistics","title":"A1.8. Additional Questions - Training logistics","text":"<p>These are suggested questions that may be of interest (not compulsory):</p> <p><code>1</code>. What would be the preferred length of the course? <code>preferred_length</code></p> <ul> <li>Linear scale 1-5 Days</li> </ul> <p><code>2</code>. How did you like the facilities/localities of the course (rooms and surroundings)? <code>course_localities</code></p> <ul> <li>Linear scale 1-5</li> <li><code>1</code>. Not at all</li> <li><code>5</code>. Very much</li> </ul> <p><code>3</code>. How did you like the lunch(es) and \u201cfika(s)\u201d? lunch_fikas</p> <ul> <li>Linear scale 1-5</li> <li><code>1</code>. Not at all</li> <li><code>5</code>. Very much</li> </ul> <p><code>4</code>. Any other comments? <code>Comments_2</code></p> <p>It was a great experience and we are working hard to make it even better. Now go make something great!</p>"},{"location":"introduction/","title":"1. Introduction","text":"<p>On 2025-01-20 the NBIS Training Steering Group had a meeting on course evaluations. The first question was 'How are evaluations evaluated?'.</p> What are the ELIXIR evaluation questions? <p>Read the ELIXIR evaluation questions.</p> <p>This paper deals only with the mandatory questions 5 to and including 9.</p> <p>It is common practice that courses are evaluated by surveys <code>[Brazas &amp; Ouellette, 2016][Gurwitz et al., 2020][Jordan et al., 2018]</code>.</p> <p>Although these surveys are developed with the best intentions, it does not necessarily mean that the questions in such surveys are useful. For example, 2 out of 3 teachers of one NBIS course have the shared verdict that the NBIS questions are -I quote- 'useless', where 1 is neutral and reasoning 'it is what we commonly do'.</p> Source? <p>This story started with one teacher's written-down criticism going through the ELIXIS evaluation, where he uses the term 'useless'.</p> <p>This was followed by the meeting notes where it was decided unanymously against using the survey in unmodified form. In this meeting, only orally, the verdict on this survey was:</p> <ul> <li>2x: useless</li> <li>1x: neutral, as '[such surveys] is what we commonly do'</li> </ul> <p>This disagreement is used as a starting point in evaluating the NBIS course evaluation questions, where the literature is searched for how these questions came to be and by which criteria the best were selected, in the hope of establishing the usefulness of this survey, as well as suggestions for improvements.</p> Which alternatives are suggested? <p>One alternative that is suggested is to use learning outcomes:</p> <ul> <li>An example evaluation using learning outcomes</li> </ul> <p>Another alternative that is suggested is to ask for written feedback only to rate teachers:</p> <ul> <li>An example reflection that used written feedback for its teachers</li> </ul> <p>Also, there is a clear rule to assess the usefulness of an evaluation questions: 'An evaluation question is useful if it is used in a reflection'. Reflections that apply these rules:</p> <ul> <li>Example 1, where some questions are assessed to be useless</li> <li>Example 2, where all questions are used</li> </ul> <p>Besides discussing the current survey question, this paper is the first to give a fully transparent process on how, with the same goals in mind, a similar set of evaluation questions were developed and how the best questions of this set were selected, with the goal of helping to make course evaluations (even) more useful.</p>"},{"location":"introduction/#11-references","title":"1.1. References","text":"<ul> <li><code>[Brazas &amp; Ouellette, 2016]</code>   Brazas, Michelle D., and BF Francis Ouellette.   \"Continuing education workshops in bioinformatics positively impact  research and careers.\" PLoS computational biology 12.6 (2016): e1004916.</li> <li><code>[Gurwitz et al., 2020]</code>   Gurwitz, Kim T., et al.   \"A framework to assess the quality and impact of bioinformatics training   across ELIXIR.\" PLoS computational biology 16.7 (2020): e1007976.   website</li> <li><code>[Jordan et al., 2018]</code>   Jordan, Kari, Fran\u00e7ois Michonneau, and Belinda Weaver.   \"Analysis of Software and Data Carpentry\u2019s pre-and post-workshop surveys.\"   Software Carpentry. Retrieved April 13 (2018): 2023.   PDF</li> </ul>"},{"location":"methods_1/","title":"3.1. Methods 1","text":"Which research question does this answer? <p>This part of the methods is related to RQ1:</p> <p>What is the history of the ELIXIR evaluation questions?</p> <p>A literature search is performed to find out the history of the current ELIXIR evaluation questions, with a focus on answering the following sub-questions:</p> <ul> <li>How were these evaluation questions developed?</li> <li>By which criteria where the best questions selected?</li> </ul> <p>The results can be found at RQ1 results.</p>"},{"location":"methods_2/","title":"3.2. Methods 2","text":"Which research question does this answer? <p>This part of the methods is related to RQ2:</p> <p>How does the academic literature relate to the ELIXIR evaluation questions?</p> <p>A literature search is performed to assess the questions in the ELIXIR SFT.</p> <p>The results can be found at RQ2 results.</p>"},{"location":"methods_3/","title":"3.3. Methods 3","text":"Which research question does this answer? <p>This part of the methods is related to RQ3:</p> <p>Which ELIXIR evaluation questions are concluded from a fully transparent process?</p> <p>To find out which evaluation questions are concluded from a fully transparent process, we use a procedure that involves multiple phases (as shown in figure <code>M3-F1</code>, each having goals as shown in table <code>M3-T1</code></p> <p></p> <p>Figure <code>M3-F1</code>. Overview of the procedure</p> Phase Goal 1 Collect all questions that are considered 'good' by at least 1 NBIS trainer 2 Collect all questions that are considered 'good' by NBIS and ELIXIR 3 Collect all reasons for and against each question 4 Rate all questions 5 Select the questions that are considered good by the NBIS community 6 Merge overlapping questions <p>Table <code>M3-T1</code>: goals of each phase in the procedure</p> <p>Here each step of the procedure is described.</p>"},{"location":"methods_3/#331-phase-1","title":"3.3.1. Phase 1","text":"<p>The goal of phase 1 is to collect all questions that are considered 'good' by at least 1 NBIS trainer.</p> <p>To do so, trainers need to</p> <ul> <li>be aware of this experiment</li> <li>know the goals of ELIXIR</li> <li>be invited to submit their questions</li> <li>do this before a deadline</li> </ul> <p>At an NBIS Training Liaison meeting, introduce this procedure to the people involved in training, as well as advertise in the relevant communication channels. Present, or share an online presentation online that shows the rationale behind this experiment, as well as the goals of ELIXIR.</p> <p>In an online anonymous survey, repeat the rationale of this experiment, as well as the ELIXIR goal of the evaluation.</p> <p>Set a deadline of several weeks. Remind trainers to submit 1 week before the deadline ends.</p> <p>Collect all questions that teachers think are useful anonymously, creating data_set_1_raw.csv.</p> <p>If less than 10 questions are collected, this experiment is cancelled. If more than 10 questions are collected, the authors of this paper are allowed to add their favorite questions too.</p> How does that data set look like? <p>Here is an example:</p> <pre><code>question,reply\nWhat is your favorite animal?,Open question\nWhat is your favorite color?,Open question\nWhat is your favorite colour?,Open question\nWhat is your favorite color?,orange;red\nWhat is your favorite animal?,Open question\n</code></pre> <p>As there may be duplicates in the data set, remove the duplicates transparently, creating data_set_1.csv and describe the process to do so in data_set_1_merge.md.</p> How does that data set look like? <p>Here is an example:</p> <pre><code>question,reply\nWhat is your favorite animal?,Open question\nWhat is your favorite color?,Open question\nWhat is your favorite color?,orange;red\n</code></pre> How does the process description look like? <p>Here is an example:</p> <pre><code># Data set 1 merge\n\nThere were 5 questions.\n\nOf those 5, here are 2 questions with different spelling:\n\n```text\nWhat is your favorite color?,Open question\nWhat is your favorite colour?,Open question\n```\n\nRJCB removed the one with `colour`, resulting in 4 questions.\n\nOf the remaining 4, here are 2 identical questions:\n\n```text\nWhat is your favorite animal?,Open question\nWhat is your favorite animal?,Open question\n```\n\nRJCB removed one of these duplicates, resulting in 3 questions.\n</code></pre> Where is the processing of raw data described? <p>See Methods 3 phase 1 processing.</p>"},{"location":"methods_3/#332-phase-2","title":"3.3.2. Phase 2","text":"<p>Combine <code>Data Set 1</code> with the current NBIS questions. Shuffle these questions randomly, creating data_set_2.csv</p> How does that data set look like? <p>Here is an example:</p> <pre><code>question,reply\nWhat is your favorite color?,orange;red\nWould you recommend the course?,Yes;No;Maybe\nWhat is your favorite animal?,Open question\nWhat is your favorite color?,Open question\n</code></pre>"},{"location":"methods_3/#333-phase-3","title":"3.3.3. Phase 3","text":"<ul> <li>Per question, as the teachers anonymously for reasons why   they would be for or against each question.   The collection of reasonings per questions results in   data_set_3.csv</li> </ul> How does that data set look like? <p>Here is an example:</p> <p></p> <pre><code>question,reply,vote,reason\nWhat is your favorite color?,orange;red,Con,Irrelevant to the course\nWould you recommend the course?,Yes;No;Maybe,Con,This is irrelavant for course quality\nWould you recommend the course?,Yes;No;Maybe,Pro,This is a good proxy for course quality\nWhat is your favorite animal?,Open question,Con,Irrelevant to the course\nWhat is your favorite animal?,Open question,Pro,Would be nice to know\nWhat is your favorite color?,Open question,Con,Irrelevant to the course\n</code></pre>"},{"location":"methods_3/#334-phase-4","title":"3.3.4. Phase 4","text":"<ul> <li>Per question, and its pros and cons, vote anonymously if the question   is useful enough to be included in a survey. Allow 'no', 'yes' and neutral   data_set_4.csv</li> </ul> How does that data set look like? <p>Here is an example:</p> <pre><code>question,reply,vote\nWhat is your favorite color?,orange;red,No\nWhat is your favorite color?,orange;red,No\nWhat is your favorite color?,orange;red,Neutral\nWould you recommend the course?,Yes;No;Maybe,No\nWould you recommend the course?,Yes;No;Maybe,Yes\nWould you recommend the course?,Yes;No;Maybe,Yes\nWhat is your favorite animal?,Open question,No\nWhat is your favorite animal?,Open question,No\nWhat is your favorite animal?,Open question,Yes\nWhat is your favorite color?,Open question,No\nWhat is your favorite color?,Open question,No\nWhat is your favorite color?,Open question,Neutral\n</code></pre>"},{"location":"methods_3/#335-phase-5","title":"3.3.5. Phase 5","text":"<p>From the questions and votes, select the set of questions that had more 'yes' than 'no' votes: these are the questions that this NBIS community thinks are useful.</p> How does that data set look like? <p>From the example data, this would be the result:</p> <pre><code>question,reply,vote\nWould you recommend the course?,Yes;No;Maybe\n</code></pre> <p>The results can be found at data_set_5.csv.</p>"},{"location":"methods_3/#336-phase-6","title":"3.3.6. Phase 6","text":"<p>From the questions that had more 'yes' than 'no' votes, merge potential overlap in questions.</p> <p>The results can be found at data_set_6.csv.</p>"},{"location":"methods_3_phase_1_processing/","title":"3.1. Methods 3 Phase 1 Processing","text":"<p>The goals of this page is to transparantly process the data from the 'Methods 3', phase 1.</p> <p>The raw data can be found at <code>data_set_1_raw.csv</code>, where the resulting processed data can be found at <code>data_set_1_merged.csv</code>,</p> <p>Filtered out are:</p> <ul> <li>administrative questions, e.g. email addresses</li> <li>duplicates</li> </ul> Overview of the steps shown here <p>An overview of the steps is shown here:</p> <p></p> <pre><code>flowchart TB\ndata_set_in[data_set_1_raw.csv]\nsubmissions[17 submissions]\nquestions_with_duplicates[43 questions with duplicates]\nunique_questions[41 unique questions]\ndata_set_out[data_set_1_merged.csv]\n\ndata_set_in --&gt; |Read| submissions\nsubmissions --&gt; |Step 1: Split up in questions, filter for usefulness| questions_with_duplicates\nquestions_with_duplicates --&gt; |Step 2: Remove duplicates| unique_questions\nunique_questions --&gt; |Save| data_set_out</code></pre>"},{"location":"methods_3_phase_1_processing/#311-step-1-split-up-in-questions-filter-for-usefulness","title":"3.1.1 Step 1: Split up in questions, filter for usefulness","text":"<p>Here is are the verbatim suggestions without time stamps, with an identifier added.</p> <p>The first denotes the set number, the second number denotes the ID within that set.</p> <p>Table 3.1.0: overview of all sets</p> Set number Description 1 All submissions 2 All questions 3 All unique questions <p>Table 3.1.0: overview of all sets</p> <p>Table 3.1.1: overview of all suggestions</p> <p></p> ID Suggestion 1.1 <code>STF form here https://docs.google.com/forms/d/e/1FAIpQLSejIRO_EHppHI9vC9QCoXFOM3DsEPU43-Pa-S-Kj5coZTuZtA/viewform?usp=sharing</code> 1.2 <code>For each learning outcome, have the participants self-assess if they were fulfilled</code> 1.3 <code>What is one thing you learned that you didn't expect to?</code> 1.4 <code>What part of the training was most useful for your work/research?</code> 1.5 <code>How did you hear about this workshop? (e.g., email, community website, colleague, social media, denbi event page)</code> 1.6 <code>Was there anything you felt was missing from the workshop? (free text)</code> 1.7 <code>Do you feel you can apply the knowledge gained in your daily work? (Yes, Partially, No) If partially or not, would you be interested in a more advanced workshop focused on a specific topic? (free text)</code> 1.8 <code>The general feeling after the completion, What was difficult to understand, what would you change if you could</code> 1.9 <code>- Was the course well organised?  yes, no or a scale -Was the course content well structured and balanced between theory and hands on?yes, no or a scale -Were the material supporting the course well designed and easy to use? yes, no or a scale -What were the strengths of this course ? free text -What aspects of this course could be improved (changes, additions) ? free text -Do you have any feedback for the trainer(s), which could be positive comments or things to improve? They can be related to the effectiveness of training delivery, oral expression, ability to answer questions, attitudes, domain expertise, ease in facilitating training, or any other.  free text -Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? scale and or free text</code> 1.10 <code>How useful were the training materials (slides, datasets, exercises)? Scale from 1 (not) to 10 (very much)</code> 1.11 <code>What improvements would you suggest for the materials? Free text</code> 1.12 <code>I feel confident applying what I learned in my future work. Scale from 1 (not) to 10 (very much)</code> 1.13 <code>What would help you apply this training more effectively? Free text</code> 1.14 <code>I suggest to add: 1. Was the theoretical content useful to carry out the exercises? 2. Were there sufficient trainers and helpers to answer your questions?</code> 1.15 <code>The question 'Any (other) feedback?' with a textbox that can be edited freely (i.e. no max count of words)</code> 1.16 <code>For all teachers: 'Say something positive about teacher X' and 'Say something teacher X can improve', both with text boxes that can be edited freely (i.e. no min nor max word count)</code> 1.17 <code>For all learning outcomes:  Give you confidence levels of the following statements, using this scale:  0: I don't know even what this is about ...? 1: I have no confidence I can do this 2: I have low confidence I can do this 3: I have some confidence I can do this 4: I have good confidence I can do this 5: I absolutely can do this!  Then let people pick either no answer or one of these answers.</code> <p>Table 3.1.1: overview of all suggestions</p> <p>The goal of this step is to split up suggestions into questions that help assess course quality (i.e. filter out administrative questions). Additionally, an 'answer type' will be assigned to each suggestion. See table 3.1.2 for the answer types, descriptions and examples.</p> <p>Table 3.1.2: description of all answer types</p> <p></p> Answer type Description GUI element name Example <code>RG1</code> A multiple choice answer where 1 option must be chosen A radio button group <code>RG01</code> A multiple choice answer where 0 or 1 options can be chosen A radio button group <code>FT1</code> FTN, 1 line A line edit <code>FTN</code> FTN, any amount of lines A text edit <code>CG1N</code> A multiple choice answer where 1 or more options can be checked A checkbox group <code>CYN</code> A checkbox that can be checked yes/no A checkbox <code>S5</code> A scale with 5 elements A slider <code>Sx</code> A scale with <code>x</code> elements A slider N/A <code>Su</code> A scale with an unknown/unspecified number of  elements A slider N/A <code>U</code> Unknown/unspecified N/A N/A <p>Description of all answer types\"</p> <p>Duplicates will be removed in the next step.</p>"},{"location":"methods_3_phase_1_processing/#submission-11","title":"Submission 1.1","text":"ID Suggestion 1.1 <code>STF form here https://docs.google.com/forms/d/e/1FAIpQLSejIRO_EHppHI9vC9QCoXFOM3DsEPU43-Pa-S-Kj5coZTuZtA/viewform?usp=sharing</code> <p>This suggestion contains a link to the NBIS Short Term Feedback (STF) survey.</p> <p>Here I collect all questions from that survey and determine if these are useful to assess course quality</p> ID Suggestion 1.1.1 <code>[FT1]</code> Event code <p>This is an adminstrative question and will be filtered out.</p> ID Suggestion 1.1.2 <code>[RG1]</code> What is your career stage? <code>-</code> Undergraduate student <code>-</code> Masters student <code>-</code> PhD candidate <code>-</code> Postdoctoral researcher <code>-</code> Senior scientist/Principal investigator <code>-</code> Research assistant/ Technician / Support staff <code>-</code> Research engineer/Staff scientist/Technical scientist <code>-</code> Industry scientist <code>-</code> Other: <code>[FT1]</code> <p>This multiple choice question ('MCQ') is an adminstrative question and will be filtered out.</p> ID Suggestion 1.1.3 <code>[CG1N]</code> University/Organisation. Please select all relevant choices. <code>-</code> Chalmers <code>-</code> G\u00f6teborgs Universitet <code>-</code> Karolinska Institutet <code>-</code> Kungliga Tekniska H\u00f6gskolan, KTH <code>-</code> Link\u00f6pings Universitet <code>-</code> Lule\u00e5 Universitet <code>-</code> Lunds Universitet <code>-</code> Naturhistoriska Riksmuseet <code>-</code> \u00d6rebro Universitet <code>-</code> Stockholms Universitet <code>-</code> Sveriges lantbruksuniversitet, SLU <code>-</code> Ume\u00e5 Universitet <code>-</code> Uppsala Universitet <code>-</code> SciLifeLab <code>-</code> Other: <code>[FT1]</code> <p>This is an adminstrative question and will be filtered out.</p> ID Suggestion 1.1.4 <code>[RG1]</code> What is your gender? <code>-</code> Man <code>-</code> Woman <code>-</code> Prefer not to say <code>-</code> Non-binary <code>-</code> Other: <code>[FT1]</code> <p>This is an adminstrative question and will be filtered out.</p> ID Suggestion 1.1.5 <code>[RG1]</code> Have you used the tools/resources covered in the course before? <code>-</code> Never - unaware of them <code>-</code> Never - used others <code>-</code> Never - aware of them, but not used them <code>-</code> Occasionally (once in a while to monthly) <code>-</code> Frequently (weekly to daily) <p>This is a question to assess course quality, as it is part of a session called 'Quality metrics'. It will be labelled <code>2.1</code>.</p> <p>On its own, asking learners to share if they used a certain tool before is useless in improving a course, even though it may to get an idea of curiousity or initial knowledge.</p> <p>However, together with a question to ask the learner to if they will use the tools again may be a way to get an idea of course quality, expressed in the change of (likelihood of) using tools.</p> ID Suggestion 1.1.6 <code>[RG1]</code> Will you use the tools/resources covered in the course again? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe <p>This is a question to assess course quality, as it is part of a session called 'Quality metrics'. It will be labelled <code>2.2</code>.</p> ID Suggestion 1.1.7 <code>[RG1]</code> Would you recommend this course? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe <p>This is a question to assess course quality, as it is part of a session called 'Quality metrics'. It will be labelled <code>2.3</code>.</p> ID Suggestion 1.1.8 <code>[RG1]</code> What is your overall rating for the course? <code>-</code> Excellent (5) <code>-</code> Very Good (4) <code>-</code> Good (3) <code>-</code> Satisfactory (2) <code>-</code> Poor (1) <p>This is a question to assess course quality, as it is part of a session called 'Quality metrics'. It will be labelled <code>2.4</code>.</p> ID Suggestion 1.1.9 <code>[FTN]</code> What part of the training did you enjoy the most? <p>This is a question to assess course quality. It will be labelled <code>2.5</code>.</p> ID Suggestion 1.1.10 <code>[FTN]</code> What part of the training did you enjoy the least? <p>This is a question to assess course quality. It will be labelled <code>2.6</code>.</p> ID Suggestion 1.1.11 <code>[RG1]</code> The balance of theoretical and practical content was <code>-</code> Too theoretical <code>-</code> Too practical <code>-</code> About right <p>This is a question to assess course quality. It will be labelled <code>2.7</code>.</p> ID Suggestion 1.1.12 <code>[RG1]</code> How do you rate the pre-course information given? <code>-</code> 1 (Very unsatisfactory/Not useful) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very good/Very useful) <p>This is a question to assess course quality. It will be labelled <code>2.8</code>.</p> ID Suggestion 1.1.13 <code>[RG1]</code> Please rate each session of the course <code>-</code> Did not attend <code>-</code> Poor (1) <code>-</code> Satisfactory (2) <code>-</code> Good (3) <code>-</code> Very Good (4) <code>-</code> Excellent (5) <code>-</code> Other: <code>[FT1]</code> <p>This is a question to assess course quality. It will be labelled <code>2.9</code>.</p> ID Suggestion 1.1.14 <code>[FTN]</code> Comments on teaching staff. Help our teaching staff to improve by providing constructive feedback <p>This is a question to assess course quality. It will be labelled <code>2.10</code>.</p> ID Suggestion 1.1.15 <code>[RG1]</code> Was the course held at a teaching level matching your training? Please describe in \"Other\" if you want to give any additional information to the Course leader(s) <code>-</code> Yes <code>-</code> No <code>-</code> Other: <code>[FT1]</code> <p>This is a question to assess course quality. It will be labelled <code>2.11</code>.</p> ID Suggestion 1.1.16 <code>[FTN]</code> Statements regarding what participants could do before the training event (customised to a specific training) <p>This is a question to assess course quality. It will be labelled <code>2.12</code>.</p> <p>On its own, asking learners to self-assess the learning outcomes is useless in improving a course, even though it does help establish course relevancy.</p> <p>However, together with a question to ask the learner to self-assess the learning outcomes at the end of a course, this is way to get an idea of course quality, expressed in the change of self-rated confidence in the learning outcomes.</p> ID Suggestion 1.1.17 <code>[FTN]</code> Statements regarding what participants can do after the training event (customised to a specific training) <p>This is a question to assess course quality. It will be labelled <code>2.13</code>.</p> ID Suggestion 1.1.18 <code>[FTN]</code> What other topics would you like to see covered in the future? <p>This is an adminstrative question and will be filtered out.</p> <p>I do see how this question may indirectly assesses course quality: if topics are suggested for future courses, this may somehow be correlated to higher course quality of the course given.</p> ID Suggestion 1.1.19 <code>[FTN]</code> Any other comments? <p>This is a question to assess course quality. It will be labelled <code>2.15</code>.</p> ID Suggestion 1.1.20 <code>[RG1]</code> What would be the prefered length of the course? <code>-</code> 1 day <code>-</code> 2 days <code>-</code> 3 days <code>-</code> 4 days <code>-</code> 5 days <p>This not to be a question to assess course quality: this question asks the learners for their preferences, which may be useful to help change the duration of a course. It will be filtered out.</p> ID Suggestion 1.1.21 <code>[RG1]</code> What is the best format for this course? <code>-</code> Onsite <code>-</code> Online <code>-</code> Online but spaced out <code>-</code> Other: <code>[FT1]</code> <p>This is not a question to assess course quality: this question asks the learners for their preferences, which may be useful to help change the format of a course. It will be filtered out.</p> ID Suggestion 1.1.22 <code>[RG1]</code> How did you like the localities of the course (rooms and surrondings)? <code>-</code> 1 (Not at all) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very much) <p>This is a question to assess course quality, as it helps evaluate the quallity of the learning environment It will be labelled <code>2.41</code>.</p> ID Suggestion 1.1.23 <code>[RG1]</code> How did you like the lunch(es) and \"fika(s)\"? <code>-</code> 1 (Not at all) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very much) <p>I consider this not to be a question to assess course quality. It will be filtered out.</p> ID Suggestion 1.1.24 <code>[FTN]</code> Any other comments? <p>I consider this not to be a question to assess course quality, as it is part of a 'Training logistics' session. Taking a look at the other questions in that session, this question is about any other comments on the training logistics. That means that this is not a question about course quality. It will be filtered out.</p>"},{"location":"methods_3_phase_1_processing/#submission-12","title":"Submission 1.2","text":"ID Suggestion 1.2 For each learning outcome, have the participants self-assess if they were fulfilled <p>This is a question to assess course quality. It is unclear in what form the question needs to be answered: should it be a yes/no checkbox, or a scale?</p> <p>It will be labelled <code>2.16</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-13","title":"Submission 1.3","text":"ID Suggestion 1.3 What is one thing you learned that you didn't expect to? <p>This is a question to assess course quality. It will be labelled <code>2.17</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-14","title":"Submission 1.4","text":"ID Suggestion 1.4 What part of the training was most useful for your work/research?` <p>This is a question to assess course quality. It will be labelled <code>2.18</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-15","title":"Submission 1.5","text":"ID Suggestion 1.5 How did you hear about this workshop? (e.g., email, community website, colleague, social media, denbi event page) <p>This is an adminstrative question and will be filtered out.</p> <p>I do see how this question may indirectly assesses course quality: if colleagues recommend the course, this may somehow be correlated to higher course quality.</p>"},{"location":"methods_3_phase_1_processing/#submission-16","title":"Submission 1.6","text":"ID Suggestion 1.6 Was there anything you felt was missing from the workshop? (free text) <p>This is a question to assess course quality. It will be labelled <code>2.19</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-17","title":"Submission 1.7","text":"ID Suggestion 1.7.1 Do you feel you can apply the knowledge gained in your daily work? (Yes, Partially, No) <p>This is a question to assess course quality. It will be labelled <code>2.20</code>.</p> ID Suggestion 1.7.2 If partially or not, would you be interested in a more advanced workshop focused on a specific topic? (free text) <p>This is an adminstrative question and will be filtered out.</p> <p>I do see how this question may indirectly assesses course quality: if there is a desire to do a follow-up workshop, this may somehow be correlated to higher course quality.</p>"},{"location":"methods_3_phase_1_processing/#submission-18","title":"Submission 1.8","text":"ID Suggestion 1.8.1 The general feeling after the completion <p>This is a question to assess course quality. It will be labelled <code>2.21</code>.</p> ID Suggestion 1.8.2 What was difficult to understand <p>This is a question to assess course quality. It will be labelled <code>2.22</code>.</p> ID Suggestion 1.8.3 what would you change if you could <p>This is a question to assess course quality. It will be labelled <code>2.23</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-19","title":"Submission 1.9","text":"ID Suggestion 1.9.1 Was the course well organised?  yes, no or a scale <p>This is a question to assess course quality. It will be labelled <code>2.24</code>.</p> ID Suggestion 1.9.2 Was the course content well structured and balanced between theory and hands on? yes, no or a scale <p>This is a question to assess course quality. It will be labelled <code>2.25</code>.</p> ID Suggestion 1.9.3 Were the material supporting the course well designed and easy to use? yes, no or a scale <p>This is a question to assess course quality. It will be labelled <code>2.26</code>.</p> ID Suggestion 1.9.4 What were the strengths of this course ? free text <p>This is a question to assess course quality. It will be labelled <code>2.27</code>.</p> ID Suggestion 1.9.5 What aspects of this course could be improved (changes, additions) ? free text <p>This is a question to assess course quality. It will be labelled <code>2.28</code>.</p> ID Suggestion 1.9.6 Do you have any feedback for the trainer(s), which could be positive comments or things to improve? They can be related to the effectiveness of training delivery, oral expression, ability to answer questions, attitudes, domain expertise, ease in facilitating training, or any other.  free text <p>This is a question to assess course quality. It will be labelled <code>2.29</code>.</p> ID Suggestion 1.9.7 Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? scale and or free text` <p>This is a question to assess course quality. It will be labelled <code>2.30</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-110","title":"Submission 1.10","text":"ID Suggestion 1.10 How useful were the training materials (slides, datasets, exercises)? Scale from 1 (not) to 10 (very much) <p>This is a question to assess course quality. It will be labelled <code>2.31</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-111","title":"Submission 1.11","text":"ID Suggestion 1.11 What improvements would you suggest for the materials? Free text <p>This is a question to assess course quality. It will be labelled <code>2.32</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-112","title":"Submission 1.12","text":"ID Suggestion 1.12 I feel confident applying what I learned in my future work. Scale from 1 (not) to 10 (very much) <p>This is a question to assess course quality. It will be labelled <code>2.33</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-113","title":"Submission 1.13","text":"ID Suggestion 1.13 What would help you apply this training more effectively? Free text <p>This is a question to assess course quality. It will be labelled <code>2.34</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-114","title":"Submission 1.14","text":"ID Suggestion 1.14.1 Was the theoretical content useful to carry out the exercises? <p>This is a question to assess course quality. It will be labelled <code>2.35</code>.</p> ID Suggestion 1.14.2 Were there sufficient trainers and helpers to answer your questions? <p>This is an question about the course logistics and will be filtered out.</p>"},{"location":"methods_3_phase_1_processing/#submission-115","title":"Submission 1.15","text":"ID Suggestion 1.15 The question 'Any (other) feedback?' with a textbox that can be edited freely (i.e. no max count of words) <p>This is a question to assess course quality. It will be labelled <code>2.37</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-116","title":"Submission 1.16","text":"ID Suggestion 1.16.1 For all teachers: 'Say something positive about teacher X' with text boxes that can be edited freely (i.e. no min nor max word count) <p>This is a question to assess course quality. It will be labelled <code>2.38</code>.</p> ID Suggestion 1.16.2 For all teachers: 'Say something teacher X can improve' with text boxes that can be edited freely (i.e. no min nor max word count) <p>This is a question to assess course quality. It will be labelled <code>2.39</code>.</p>"},{"location":"methods_3_phase_1_processing/#submission-117","title":"Submission 1.17","text":"ID Suggestion 1.17 <code>[Multiple choice, no choice is allowed]</code> For all learning outcomes:  Give you confidence levels of the following statements, using this scale: <code>-</code> 0: I don't know even what this is about ...? <code>-</code> 1: I have no confidence I can do this <code>-</code> 2: I have low confidence I can do this <code>-</code> 3: I have some confidence I can do this <code>-</code> 4: I have good confidence I can do this <code>-</code> 5: I absolutely can do this! <p>This is a question to assess course quality. It will be labelled <code>2.40</code>.</p>"},{"location":"methods_3_phase_1_processing/#311-result","title":"3.1.1. Result","text":"<p>The 17 submissions resulted in 43 questions.</p> <p>Table 3.1.3: overview of all questions</p> <p></p> ID Answer type Question 2.1 <code>RG1</code> Have you used the tools/resources covered in the course before? <code>-</code> Never - unaware of them <code>-</code> Never - used others <code>-</code> Never - aware of them, but not used them <code>-</code> Occasionally (once in a while to monthly) <code>-</code> Frequently (weekly to daily) 2.2 <code>RG1</code> Will you use the tools/resources covered in the course again? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe 2.3 <code>RG1</code> Would you recommend this course? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe 2.4 <code>RG1</code> What is your overall rating for the course? <code>-</code> Excellent (5) <code>-</code> Very Good (4) <code>-</code> Good (3) <code>-</code> Satisfactory (2) <code>-</code> Poor (1) 2.5 <code>FTN</code> What part of the training did you enjoy the most? 2.6 <code>FTN</code> What part of the training did you enjoy the least? 2.7 <code>RG1</code> The balance of theoretical and practical content was <code>-</code> Too theoretical <code>-</code> Too practical <code>-</code> About right 2.8 <code>RG1</code> How do you rate the pre-course information given? <code>-</code> 1 (Very unsatisfactory/Not useful) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very good/Very useful) 2.9 <code>RG1</code> Per session: please rate each session of the course <code>-</code> Did not attend <code>-</code> Poor (1) <code>-</code> Satisfactory (2) <code>-</code> Good (3) <code>-</code> Very Good (4) <code>-</code> Excellent (5) <code>-</code> Other: <code>[FT1]</code> 2.10 <code>FTN</code> Comments on teaching staff. Help our teaching staff to improve by providing constructive feedback 2.11 <code>RG1</code> Was the course held at a teaching level matching your training? Please describe in \"Other\" if you want to give any additional information to the Course leader(s) <code>-</code> Yes <code>-</code> No <code>-</code> Other: <code>[FT1]</code> 2.12 <code>FTN</code> statements regarding what participants could do before the training event 2.13 <code>FTN</code> statements regarding what participants can do after the training event 2.14 . Removed 2.15 <code>FTN</code> Any other comments? 2.16 <code>U</code> For each learning outcome, have the participants self-assess if they were fulfilled 2.17 <code>FTN</code> What is one thing you learned that you didn't expect to? 2.18 <code>FTN</code> What part of the training was most useful for your work/research? 2.19 <code>FTN</code> Was there anything you felt was missing from the workshop? 2.20 <code>RG1</code> Do you feel you can apply the knowledge gained in your daily work? <code>-</code> Yes <code>-</code> Partially <code>-</code> No 2.21 <code>FTN</code> The general feeling after the completion 2.22 <code>FTN</code> What was difficult to understand 2.23 <code>FTN</code> What would you change if you could 2.24a <code>CYN</code> Was the course well organised? 2.24b <code>Su</code> Was the course well organised? 2.25a <code>CYN</code> Was the course content well structured and balanced between theory and hands on? 2.25b <code>Su</code> Was the course content well structured and balanced between theory and hands on? 2.26a <code>CYN</code> Were the material supporting the course well designed and easy to use? 2.26b <code>Su</code> Were the material supporting the course well designed and easy to use? 2.27 <code>FTN</code> What were the strengths of this course ? 2.28 <code>FTN</code> What aspects of this course could be improved (changes, additions) ? 2.29 <code>FTN</code> Do you have any feedback for the trainer(s), which could be positive comments or things to improve? They can be related to the effectiveness of training delivery, oral expression, ability to answer questions, attitudes, domain expertise, ease in facilitating training, or any other 2.30a <code>Su</code> Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? 2.30b <code>FTN</code> Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? 2.31 <code>RG1</code> How useful were the training materials (slides, datasets, exercises)? Scale from 1 (not) to 10 (very much) 2.32 <code>FTN</code> What improvements would you suggest for the materials? 2.33 <code>RG1</code> I feel confident applying what I learned in my future work. Scale from 1 (not) to 10 (very much) 2.34 <code>FTN</code> What would help you apply this training more effectively? 2.35 <code>U</code> Was the theoretical content useful to carry out the exercises? 2.36 . Removed 2.37 <code>FTN</code> Any (other) feedback? 2.38 <code>FTN</code> For all teachers: 'Say something positive about teacher X' 2.39 <code>FTN</code> For all teachers: 'Say something teacher X can improve' 2.40 <code>RG01</code> For all learning outcomes:  Give you confidence levels of the following statements, using this scale: <code>-</code> 0: I don't know even what this is about ...? <code>-</code> 1: I have no confidence I can do this <code>-</code> 2: I have low confidence I can do this <code>-</code> 3: I have some confidence I can do this <code>-</code> 4: I have good confidence I can do this <code>-</code> 5: I absolutely can do this! 2.41 <code>RG1</code> How did you like the localities of the course (rooms and surrondings)? <code>-</code> 1 (Not at all) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very much) <p>Table 3.1.3: overview of all questions. See table 3.1.2 for the descrptions of the answer type</p>"},{"location":"methods_3_phase_1_processing/#312-step-2-remove-duplicates","title":"3.1.2. Step 2: remove duplicates","text":"<p>Here we remove the duplicates from Table 3.1.3. We do so by adding a new ID to each unique question, where the first number (always a <code>3</code> here) denotes the step (in this case, the step to remove duplicate questions), and the second number denotes the ID within that set of unique questions.</p> <p>In this table, we remove the duplicates:</p> <p>Table 3.2.2: overview of all unique questions</p> <p></p> ID ID Question summary Answer type Question 2.1 3.1 Use resources before <code>RG1</code> Have you used the tools/resources covered in the course before? <code>-</code> Never - unaware of them <code>-</code> Never - used others <code>-</code> Never - aware of them, but not used them <code>-</code> Occasionally (once in a while to monthly) <code>-</code> Frequently (weekly to daily) 2.2 3.2 Use resources after <code>RG1</code> Will you use the tools/resources covered in the course again? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe 2.3 3.3 Course recommend <code>RG1</code> Would you recommend this course? <code>-</code> Yes <code>-</code> No <code>-</code> Maybe 2.4 3.4 Course rating <code>RG1</code> What is your overall rating for the course? <code>-</code> Excellent (5) <code>-</code> Very Good (4) <code>-</code> Good (3) <code>-</code> Satisfactory (2) <code>-</code> Poor (1) 2.5 3.5 Enjoy most <code>FTN</code> What part of the training did you enjoy the most? 2.6 3.6 Enjoy least <code>FTN</code> What part of the training did you enjoy the least? 2.7 3.7 Balance theory/practice <code>RG1</code> The balance of theoretical and practical content was <code>-</code> Too theoretical <code>-</code> Too practical <code>-</code> About right 2.8 3.8 Rate pre-course info <code>RG1</code> How do you rate the pre-course information given? <code>-</code> 1 (Very unsatisfactory/Not useful) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very good/Very useful) 2.9 3.9 Rate sessions <code>RG1</code> Per session: please rate each session of the course <code>-</code> Did not attend <code>-</code> Poor (1) <code>-</code> Satisfactory (2) <code>-</code> Good (3) <code>-</code> Very Good (4) <code>-</code> Excellent (5) <code>-</code> Other: <code>[FT1]</code> 2.10 3.10 Comment teaching staff <code>FTN</code> Comments on teaching staff. Help our teaching staff to improve by providing constructive feedback 2.11 3.11 Content matching level <code>RG1</code> Was the course held at a teaching level matching your training? Please describe in \"Other\" if you want to give any additional information to the Course leader(s) <code>-</code> Yes <code>-</code> No <code>-</code> Other: <code>[FT1]</code> 2.12 3.12 Self assess LOs before <code>FTN</code> statements regarding what participants could do before the training event 2.13 3.14 Self assess LOs after <code>FTN</code> statements regarding what participants can do after the training event 2.15 3.15 Comments <code>FTN</code> Any other comments? 2.16 3.14 Self-assess LOs after <code>U</code> For each learning outcome, have the participants self-assess if they were fulfilled 2.17 3.17 Unexpected learning <code>FTN</code> What is one thing you learned that you didn't expect to? 2.18 3.18 Most useful part <code>FTN</code> What part of the training was most useful for your work/research? 2.19 3.19 Feel missing <code>FTN</code> Was there anything you felt was missing from the workshop? 2.20 3.20a Feel can apply <code>RG1</code> Do you feel you can apply the knowledge gained in your daily work? <code>-</code> Yes <code>-</code> Partially <code>-</code> No 2.21 3.21 Feeling afterwards <code>FTN</code> The general feeling after the completion 2.22 3.22 Hard to understand <code>FTN</code> What was difficult to understand 2.23 3.23 Any change <code>FTN</code> What would you change if you could 2.24a 3.24a Course organisation <code>CYN</code> Was the course well organised? 2.24b 3.24b Course organisation <code>Su</code> Was the course well organised? 2.25a 3.25a Course content structure <code>CYN</code> Was the course content well structured and balanced between theory and hands on? 2.25b 3.25b Course content structure <code>Su</code> Was the course content well structured and balanced between theory and hands on? 2.26a 3.26a Course material design <code>CYN</code> Were the material supporting the course well designed and easy to use? 2.26b 3.26a Course material design <code>Su</code> Were the material supporting the course well designed and easy to use? 2.27 3.27 Course strength <code>FTN</code> What were the strengths of this course ? 2.28 3.28 Improve course <code>FTN</code> What aspects of this course could be improved (changes, additions) ? 2.29 3.29 Feedback trainer <code>FTN</code> Do you have any feedback for the trainer(s), which could be positive comments or things to improve? They can be related to the effectiveness of training delivery, oral expression, ability to answer questions, attitudes, domain expertise, ease in facilitating training, or any other 2.30a 3.30a Able to apply <code>Su</code> Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? 2.30b 3.30b Able to apply <code>FTN</code> Were you able to transpose and apply the theorical and practical knowledge into your own research work/scientific question? 2.31 3.31 Materials usefulness <code>RG1</code> How useful were the training materials (slides, datasets, exercises)? Scale from 1 (not) to 10 (very much) 2.32 3.32 Improvement materials <code>FTN</code> What improvements would you suggest for the materials? 2.33 3.33 Confidence course <code>RG1</code> I feel confident applying what I learned in my future work. Scale from 1 (not) to 10 (very much) 2.34 3.34 Suggest help to apply <code>FTN</code> What would help you apply this training more effectively? 2.35 3.35 Theory usefulness <code>U</code> Was the theoretical content useful to carry out the exercises? 2.36 . . . Removed 2.37 3.37 Any feedback <code>FTN</code> Any (other) feedback? 2.38 3.38 Positive teacher <code>FTN</code> For all teachers: 'Say something positive about teacher X' 2.39 3.39 Improve teacher <code>FTN</code> For all teachers: 'Say something teacher X can improve' 2.40 3.14 Self assess LOs after <code>RG01</code> For all learning outcomes:  Give you confidence levels of the following statements, using this scale: <code>-</code> 0: I don't know even what this is about ...? <code>-</code> 1: I have no confidence I can do this <code>-</code> 2: I have low confidence I can do this <code>-</code> 3: I have some confidence I can do this <code>-</code> 4: I have good confidence I can do this <code>-</code> 5: I absolutely can do this! 2.41 3.40 Like locality <code>RG1</code> How did you like the localities of the course (rooms and surrondings)? <code>-</code> 1 (Not at all) <code>-</code> 2 <code>-</code> 3 <code>-</code> 4 <code>-</code> 5 (Very much) <p>Table 3.2.2: overview of all questions (first column) and all unique questions (second column). Questions that are duplicates have an ID that is in bold. See table 3.1.2 for the descrptions of the answer type</p>"},{"location":"methods_3_phase_1_processing/#312-result","title":"3.1.2. Result","text":"<p>The 43 questions resulted in 41 unique questions.</p>"},{"location":"methods_4/","title":"3.4. Methods 4","text":"Which research question does this answer? <p>This part of the methods is related to RQ4:</p> <p>How different are the newly suggested questions from the current ones?</p> <p>The results can be found at RQ4 results.</p>"},{"location":"research_questions/","title":"2. Research questions","text":"<ul> <li>RQ1: What is the history of the ELIXIR evaluation questions?   How were they developed?   By which criteria where the best questions selected?</li> <li>RQ2: How does the academic literature relate to the ELIXIR evaluation   questions?</li> <li>RQ3: Which ELIXIR evaluation questions are concluded from a fully   transparent process?</li> <li>RQ4: How different are the newly suggested questions from the current ones?</li> </ul>"},{"location":"results_1/","title":"4.1. Results of RQ1: What is the history of the ELIXIR evaluation questions?","text":"What are the ELIXIR evaluation questions? <p>Read the ELIXIR evaluation questions.</p> <p>This paper deals only with the mandatory questions 5 to and including 9.</p>"},{"location":"results_1/#411-what-is-the-ancestry-of-the-nbis-questions","title":"4.1.1. What is the ancestry of the NBIS questions?","text":"<p>The paper where these questions were described first in <code>[Gurwitz et al., 2020]</code> . In that paper, one can read that these questions are based on <code>[Jordan et al., 2018]</code> and <code>[Brazas &amp; Ouellette, 2016]</code>. These last two papers do not reference any academic papers on where their questions originated from.</p>"},{"location":"results_1/#412-development-of-the-questions","title":"4.1.2. Development of the questions","text":"<p>ELIXIR developed these evaluation questions to, as quoted from <code>[Gurwitz et al., 2020]</code>:</p> <ul> <li>describe the audience demographic being reached   by ELIXIR training events</li> <li>assess the quality of ELIXIR training events directly   after they have taken place'</li> </ul> <p>The resulting metrics can be found at https://training-metrics-dev.elixir-europe.org/all-reports.</p> <p>This is what is written about how the ELIXIR short-term evaluation questions came to be (quote from <code>[Gurwitz et al., 2020]</code>):</p> <p>We were interested in participant satisfaction as a reflection on training quality in order to be able to inform best practice for ELIXIR training. We acknowledge that training quality is more complex than solely participant satisfaction and that the community would benefit from future work to obtain a fuller picture on training quality.</p> <p>This paragraph shows that this ELIXIR group took the liberty of adding questions besides its two primary sources.</p> <p>Again from <code>[Gurwitz et al., 2020]</code> we read:</p> <p>These metrics were developed out of those already collected by ELIXIR training providers, as well as from discussions with stakeholders, external training providers, and literature review <code>[Brazas &amp; Ouellette, 2016][Jordan et al., 2018]</code></p> <p>There are no references to the literature that was reviewed besides these two papers.</p> <p>Neither does the referred literature:</p> <ul> <li><code>[Brazas &amp; Ouellette, 2016]</code> shows the results of surveys from   bioinformatics workshops. The survey questions where   taken from other sources (i.e., the Society for Experimental Biology   and the Global Organisation for Bioinformatics Learning, Education and   Training), without any reference to the literature.   It is not described how the evaluation questions   came to be and with which reasoning the best were selected</li> <li><code>[Jordan et al., 2018]</code> shows the results of surveys from   Data Carpentry workshops.   Also here, it is not described how the evaluation questions   came to be and with which reasoning the best were selected:   this paper has zero references to the literature</li> </ul> <p>Taking a closer look at the evaluation questions of <code>[Jordan et al., 2018]</code>, we see that some questions of its evaluations were not copied to the ELIXIR evaluation. The reasoning why some questions were copied and some not is unpublished.</p> Which questions were not copied to the ELIXIR evaluation? <p>One such removed evaluation question is to let learners self-assess their confidence in learning outcomes.</p> How does such a question look like? <p>Here is an example of questions to let learners self-assess themselves (from <code>[Plaza et al., 2002]</code>):</p> <p></p> How are the analysing such questions look like? <p>Here we can see the results of learners self-assessing their competences before and after the teaching session, figure from <code>[Jordan et al., 2018]</code>:</p> <p></p> <p>Here we can see a similar results for an earlier paper <code>[Raupach et al., 2011]</code>:</p> <p></p> Should that question have been copied to the ELIXIR evaluation? <p>Probably.</p> <p>We know that this self-assessment does not relate to actual skill <code>[Liaw et al., 2012]</code> (with more studies showing this in that paper). However, there is some evidence that self-assessment is informative to evaluate a course curriculum <code>[Plaza et al., 2002]</code> and teacher effectiveness <code>[Raupach et al., 2011]</code>, although other studies argue that more measurements are needed to properly assess teacher effectiveness <code>[Darling\u2010Hammond et al., 2010]</code>.</p>"},{"location":"results_1/#413-references","title":"4.1.3. References","text":"<ul> <li><code>[Ang et al., 2018]</code> Ang, Lawrence, Yvonne Alexandra Breyer, and Joseph Pitt.   \"Course recommendation as a construct in student evaluations:   will students recommend your course?.\" Studies in Higher Education 43.6   (2018): 944-959.</li> <li><code>[Brazas &amp; Ouellette, 2016]</code>   Brazas, Michelle D., and BF Francis Ouellette.   \"Continuing education workshops in bioinformatics positively impact  research and careers.\" PLoS computational biology 12.6 (2016): e1004916.</li> <li><code>[Darling\u2010Hammond et al., 2010]</code>   Darling\u2010Hammond, Linda, Xiaoxia Newton, and Ruth Chung Wei.   \"Evaluating teacher education outcomes: A study of the Stanford Teacher   Education Programme.\" Journal of education for teaching 36.4 (2010): 369-388.</li> <li><code>[Gurwitz et al., 2020]</code>   Gurwitz, Kim T., et al.   \"A framework to assess the quality and impact of bioinformatics training   across ELIXIR.\" PLoS computational biology 16.7 (2020): e1007976.   website</li> <li><code>[Jordan et al., 2018]</code>   Jordan, Kari, Fran\u00e7ois Michonneau, and Belinda Weaver.   \"Analysis of Software and Data Carpentry\u2019s pre-and post-workshop surveys.\"   Software Carpentry. Retrieved April 13 (2018): 2023.   PDF</li> <li><code>[Liaw et al., 2012]</code>   Liaw, Sok Ying, et al. \"Assessment for simulation learning outcomes: a   comparison of knowledge and self-reported confidence with observed clinical   performance.\" Nurse education today 32.6 (2012): e35-e39.</li> <li><code>[Rox\u00e5 et al., 2021]</code> Rox\u00e5, Torgny, et al.   \"Reconceptualizing student ratings of teaching to support quality discourse   on student learning: a systems perspective.\" Higher Education (2021): 1-21.</li> <li><code>[Raupach et al., 2011]</code>   Raupach, Tobias, et al. \"Towards outcome-based programme evaluation:   using student comparative self-assessments to determine teaching   effectiveness.\" Medical teacher 33.8 (2011): e446-e453.</li> <li><code>[Plaza et al., 2002]</code>   Plaza, Cecilia M., et al.   \"Curricular evaluation using self-efficacy measurements.\"   American Journal of Pharmaceutical Education 66.1 (2002): 51-54.</li> <li><code>[Uttl et al., 2017]</code>   Uttl, Bob, Carmela A. White, and Daniela Wong Gonzalez.   \"Meta-analysis of faculty's teaching effectiveness:   Student evaluation of teaching ratings and student learning are not related.\"   Studies in Educational Evaluation 54 (2017): 22-42.</li> </ul>"},{"location":"results_2/","title":"4.2. Results of RQ2","text":"What are the ELIXIR evaluation questions? <p>Read the ELIXIR evaluation questions.</p> <p>This paper deals only with the mandatory questions 5 to and including 9.</p> <p>With the goal of the SFT ('to improve the course and its materials') in mind, here we go through the mandatory questions that resulted from the process described in the results of Research Question 1. The relevant questions are found in <code>Section 3 - Quality Metrics</code> of the NBIS short-term evaluation. Here, we go through each of these questions in detail.</p>"},{"location":"results_2/#421-question-5","title":"4.2.1. Question 5","text":"<pre><code>5. Have you used the tools/resource(s) covered in the course before?\n\n- Never - Unaware of them\n- Never - Used other service\n- Occasionally\n- Frequently\n</code></pre> <p>Question 5 is an interesting way to evaluate the quality of a course, because it is about something learners have done before the course took place. Searching the literature for 'using previous experience in course evaluations' (and sentences alike) resulted in zero hits.</p> What are the metrics for this question? <p>These are the metrics collected at 2025-01-24 7:04 Stockholm time (https://training-metrics-dev.elixir-europe.org/feedback-report):</p> Reponse n Frequency (%) Never - Unaware of them 4350 23.5 Never - aware of them 3838 20.8 Never - Used other service 1803 9.7 Occasionally 6974 37.7 Frequently 1528 8.3"},{"location":"results_2/#422-question-6","title":"4.2.2. Question 6","text":"<pre><code>6. Will you use the tools/resource(s) covered in the course again?\n\n- Yes\n- No\n- Maybe\n</code></pre> <p>Question 6 is another interesting way to evaluate the quality of a course, because it is about the usefulness of the topic being taught, combined with predicting the future. Searching the literature for 'using self-predicted future use of content in course evaluations' (and sentences alike) resulted in zero hits.</p> What are the metrics for this question? <p>These are the metrics collected at 2025-01-24 7:16 Stockholm time (https://training-metrics-dev.elixir-europe.org/feedback-report):</p> Reponse n Frequency (%) Maybe 2822 15.1 No 105 0.6 Yes 15792 84.4"},{"location":"results_2/#423-question-7","title":"4.2.3. Question 7","text":"<pre><code>7. Would you recommend the course?\n\n- Yes\n- No\n- Maybe\n</code></pre> <p>Question 7 attempt to measure course quality by asking the learner if he/she would recommend the course. This question originates from one of the two evaluations that this ELIXIR evaluation is based on (<code>[Jordan et al., 2018]</code>).</p> <p>Searching the literature for 'using course recommendation in evaluation' (and sentences alike) resulted in one relevant hit. This paper, <code>[Ang et al., 2018]</code>, shows that using this question may indeed be a valid way to asses course quality <code>[Ang et al., 2018]</code>.</p> What are the metrics for this question? <p>These are the metrics collected at 2025-01-24 8:27 Stockholm time (https://training-metrics-dev.elixir-europe.org/feedback-report):</p> Reponse n Frequency (%) Maybe 19597 89.5 No 1790 8.2 Yes 519 2.4"},{"location":"results_2/#424-question-8","title":"4.2.4. Question 8","text":"<pre><code>8. What is your overall rating for the course\n\n- Poor (1)\n- Satisfactory (2)\n- Good (3)\n- Very Good (4)\n- Excellent (5)\n</code></pre> <p>Question 8 too attempts to measure course quality by asking the learner to rate it. This question is absent from the two questionnaires (i.e. those described in <code>[Brazas &amp; Ouellette, 2016]</code> and <code>[Jordan et al., 2018]</code>) this questionnaire is based one.</p> <p>We did a modest literature search by searching Google Scholar for the most relevant papers for 'student rating of courses meta analysis' and investigating the first ten.</p> Which papers were that? <ul> <li><code>[Cohen, 1981]</code></li> <li><code>[Cohen, 1980]</code></li> <li><code>[Clayson, 2009]</code></li> <li><code>[Schiekirka and Raupach, 2015]</code></li> <li><code>[Falchikov and Boud, 1989]</code></li> <li><code>[Vo and Diep, 2017]</code></li> <li><code>[Strelan et al., 2020]</code></li> <li><code>[d'Apollonia and Abrami, 1997]</code></li> <li><code>[Benton and Cashin, 2013]</code></li> <li><code>[Denson et al., 2021]</code></li> </ul> <p>Based on the titles of the papers, 5 of these were labelled as irrelevant to this study.</p> Which papers were that? <p></p> Paper Included Intervention What is rated <code>[Cohen, 1981]</code> Yes Rating Instruction and student achievement <code>[Cohen, 1980]</code> No Written feedback Diverse <code>[Clayson, 2009]</code> Yes Rating How much students learn <code>[Schiekirka and Raupach, 2015]</code> Yes Rating Course as a whole <code>[Falchikov and Boud, 1989]</code> No Self-rating Students <code>[Vo and Diep, 2017]</code> No Blended learning Learner course performance <code>[Strelan et al., 2020]</code> No Satisfaction Flipped classroom <code>[d'Apollonia and Abrami, 1997]</code> Yes Rating Instruction <code>[Benton and Cashin, 2013]</code> Yes Rating Instruction <code>[Denson et al., 2021]</code> No Diversity Student outcome <p>Of the 5 papers relevant to this study, 2 were meta-analyses: <code>[Clayson, 2009]</code> and <code>[Benton and Cashin, 2013]</code>. The relations between the papers can be seen in the figure below:</p> <pre><code>flowchart TD\n  cohen_1981[Cohen, 1981]\n  dapollonia_and_abrami_1997[d'Apollonia and Abrami, 1997]\n  clayson_2009[Clayson, 2009]\n  benton_and_cashin_2013[Benton and Cashin, 2013]\n  schiekirka_and_raupach_2015[Schiekirka and Raupach, 2015]\n\n  %% schiekirka_and_raupach_2015 does not cite the literature\n\n  benton_and_cashin_2013 --- cohen_1981\n  benton_and_cashin_2013 --- dapollonia_and_abrami_1997\n  benton_and_cashin_2013 --- clayson_2009\n\n  clayson_2009 --- cohen_1981\n  clayson_2009 --- dapollonia_and_abrami_1997\n\n  dapollonia_and_abrami_1997 --- cohen_1981</code></pre> <p>The three meta analyses have different conclusions:</p> <ul> <li><code>[Clayson, 2009]</code>: this meta analysis concludes that there are   many papers that report a link between   learner ratings and any metric. However, this effect vanishes   for bigger studies and/or studies with rigorous metrics.   It concludes that there is no relation between   ratings given by learners and any metric.</li> <li><code>[Benton and Cashin, 2013]</code>, which also refers to <code>[Clayson, 2009]</code>,   ignores the conclusion that correlations vanish for more rigid   studes and repeats that there does exist a small positive   association between the ratings given by learners   and measures of learning</li> <li><code>[Schiekirka and Raupach, 2015]</code> (which curiously enough does not mention   the other two meta analyses) concludes that overall course ratings   are not influenced by high quality teaching. They remark with   with a reference to earlier work:   'With regard to overall course ratings, students   tended to rely on their 'gut feelings' rather than using   objective benchmarks of course quality' <code>[Schiekirka et al., 2015]</code></li> </ul> What are the rough notes made during the literature review? <p>Below are rough notes that were made during the literature review. These are made public here for full transparency and are not to be reviewed.</p> <p>All included papers are read with the goal to find how much the question 'What is your overall rating for the course?' helps 'to improve the course and its materials'.</p> <p><code>[Cohen, 1981]</code>: 'The average correlation between an overall instructor rating and student achievement was .43; the average correlation between an overall course rating and student achievement was .47.', based on 41 independent studies. There is 'strong support for the validity of student ratings as measures of teaching effectiveness'.</p> <p><code>[Clayson, 2009]</code>: this meta analysis concludes that there are many papers that report a link between learner ratings and any metric. However, this effect vanishes for bigger studies and/or studies with rigorous metrics. It concludes that there is no relation between ratings given by learners and any metric.</p> <p><code>[Schiekirka and Raupach, 2015]</code>: 'Qualitative research (2 studies) indicated that overall course ratings are mainly influenced by student satisfaction with teaching and exam difficulty rather than objective determinants of high quality teaching.' (note link to Uttl et al., here) and 'no firm conclusions can be drawn from this review'</p> <p>Also: 'With regard to overall course ratings, students tended to rely on their 'gut feelings' rather than using objective benchmarks of course quality' <code>[Schiekirka et al., 2015]</code></p> <p><code>[d'Apollonia and Abrami, 1997]</code>: 'student ratings are moderately valid; however, administrative, instructor, and course characteristics influence student ratings of instruction', uses 7 studies all before 1980.</p> <p><code>[Benton and Cashin, 2013]</code>: 'Students are very consistent in their ratings of teacher behaviors, their own learning, and of overall impressions of the course and teacher', 'Student ratings instruments that are backed by reliability and validity evidence typically assess more than what students think of the teacher', 'Combining consultation with feedback from student ratings is more useful for improving instruction than providing feedback alone.'</p> <p>Criticism on older work:</p> <p>'the correlations reported in, among others <code>[Cohen, 1981]</code>, are impressive. Moreover, because teachers are not the only cause of student learning, and probably not the most important one, one would not expect students' ratings of instruction to correlate perfectly with how much they learn in a course'</p> <p>Agreement on older work:</p> <ul> <li>'He, <code>[Clayson, 2009]</code> found, in general,   a small positive association between measures of learning and   SRIs ('student ratings of instruction'), which is   consistent with previous research'.   THIS IS A MISREPRESENTATION!</li> </ul> <p>'In general, student ratings tend to be statistically reliable, valid, and relatively free from bias or the need for control, perhaps more so than any other data used for faculty evaluation. Moreover, they can help instructors improve their teaching, especially when combined with self-reflection and consultation.' and 'Student ratings must be interpreted. We should not confuse a source of data with the evaluators who use it\u2014in combination with other kinds of information\u2014to make judgments about an instructor\u2019s teaching effectiveness (Cashin 2003)'.</p> <p>We conclude that there is no relation between training quality and ratings given by learners.</p> What are the metrics for this question? <p>These are the metrics collected at 2025-01-24 8:28 Stockholm time (https://training-metrics-dev.elixir-europe.org/feedback-report):</p> Reponse n Frequency (%) Excellent 7736 37 Very good 8437 40.4 Good 3543 17 Satisfactory 993 4.8 Poor 192 0.9"},{"location":"results_2/#425-question-9","title":"4.2.5. Question 9","text":"<pre><code>9. A. May we contact you by email in the future for more feedback?\n\n- Yes\n- No\n</code></pre> <p>Question 9 is an interesting way to measure the course quality, based on the learner being willing to answer questions on the future. It seems more likely that question should be placed outside of the section <code>Section 3 - Quality Metrics</code>.</p> <p>Searching the literature for 'using future contact in course evaluation' (and sentences alike) resulted in zero relevant hits.</p> What are the metrics for this question? <p>These are the metrics collected at 2025-01-24 8:32 Stockholm time (https://training-metrics-dev.elixir-europe.org/feedback-report):</p> Reponse n Frequency (%) No 8756 49.7 Yes 8860 50.3"},{"location":"results_2/#426-references","title":"4.2.6. References","text":"<ul> <li><code>[Ang et al., 2018]</code> Ang, Lawrence, Yvonne Alexandra Breyer, and Joseph Pitt.   \"Course recommendation as a construct in student evaluations:   will students recommend your course?.\" Studies in Higher Education 43.6   (2018): 944-959.</li> <li><code>[Brazas &amp; Ouellette, 2016]</code> Brazas, Michelle D., and BF Francis Ouellette.   \"Continuing education workshops in bioinformatics positively impact  research and careers.\" PLoS computational biology 12.6 (2016): e1004916.</li> <li><code>[Jordan et al., 2018]</code> Jordan, Kari, Fran\u00e7ois Michonneau, and Belinda Weaver.   \"Analysis of Software and Data Carpentry\u2019s pre-and post-workshop surveys.\"   Software Carpentry. Retrieved April 13 (2018): 2023.   PDF</li> <li>[Uttl et al., 2017] Uttl, Bob, Carmela A. White, and Daniela Wong Gonzalez.   \"Meta-analysis of faculty's teaching effectiveness:   Student evaluation of teaching ratings and student learning are not related.\"   Studies in Educational Evaluation 54 (2017): 22-42.</li> <li><code>[Cohen, 1981]</code> Cohen, Peter A.   \"Student ratings of instruction and student achievement:   A meta-analysis of multisection validity studies.\"   Review of educational research 51.3 (1981): 281-309.</li> <li><code>[Cohen, 1980]</code> Cohen, Peter A.   \"Effectiveness of student-rating feedback for improving college instruction:   A meta-analysis of findings.\"   Research in higher education 13.4 (1980): 321-341.</li> <li><code>[Clayson, 2009]</code> Clayson, Dennis E. \"Student evaluations of teaching:   Are they related to what students learn?   A meta-analysis and review of the literature.\"   Journal of marketing education 31.1 (2009): 16-30.</li> <li><code>[Schiekirka and Raupach, 2015]</code> Schiekirka, Sarah, and Tobias Raupach.   \"A systematic review of factors influencing student ratings   in undergraduate medical education course evaluations.\"   BMC medical education 15.1 (2015): 30.</li> <li><code>[Schiekirka et al., 2015]</code> Schiekirka, Sarah, et al.   \"Student perceptions of evaluation in undergraduate medical education:   A qualitative study from one medical school.\"   BMC medical education 12.1 (2012): 45.</li> <li><code>[Falchikov and Boud, 1989]</code> Falchikov, Nancy, and David Boud.   \"Student self-assessment in higher education: A meta-analysis.\"   Review of educational research 59.4 (1989): 395-430.</li> <li><code>[Vo and Diep, 2017]</code> Vo, Hien M., Chang Zhu, and Nguyet A. Diep.   \"The effect of blended learning on student performance at course-level   in higher education: A meta-analysis.\"   Studies in Educational Evaluation 53 (2017): 17-28.</li> <li><code>[Strelan et al., 2020]</code> Strelan, Peter, Amanda Osborn, and Edward Palmer.   \"Student satisfaction with courses and instructors in a flipped classroom:   A meta\u2010analysis.\" Journal of Computer Assisted Learning 36.3 (2020): 295-314.</li> <li><code>[d'Apollonia and Abrami, 1997]</code> d'Apollonia, Sylvia, and Philip C. Abrami.   \"Navigating student ratings of instruction.\"   American psychologist 52.11 (1997): 1198.</li> <li><code>[Benton and Cashin, 2013]</code> Benton, Stephen L., and William E. Cashin.   \"Student ratings of instruction in college and university courses.\"   Higher education: Handbook of theory and research:   Volume 29. Dordrecht: Springer Netherlands, 2013. 279-326.</li> <li><code>[Denson et al., 2021]</code> Denson, Nida, et al.   \"Do diversity courses improve college student outcomes?   A meta-analysis.\" Journal of Diversity in Higher Education 14.4 (2021): 544.</li> </ul>"},{"location":"results_3/","title":"4.3. Results of RQ3","text":"Which research question does this answer? <p>This part of the methods is related to RQ3:</p> <p>Which ELIXIR evaluation questions are concluded from a fully transparent process?</p> <p>On 2025-02-17:</p> <ul> <li>a presentation was given at the NBIS TrSG, with 5 people attending.   The presentation lasted around 10 minutes, after which there   was 15 minutes of questions</li> <li>after the meeting, a video of that presentation was recorded</li> </ul> Where can I find the presentations and video? <p>The presentations and videos can be found at presentations.</p> <ul> <li>NBIS teachers were invited to participate</li> </ul> How did the invite on Slack look like? <p>Dear trainers,</p> <p>You are all invited in an experiment to find 'good' course evaluation questions, that have the goal to assess course quality, in a way that is (1) transparent, (2) as a group, and (3) uses informed decision making. This is part of a (draft-stage) paper you can find here.</p> <p>You are invited to share your favorite evaluation question(s) in this form here.</p> <p>If you need more background:</p> <ul> <li>You can find the presentation on this on YouTube here</li> <li>You can view the presentation slides here</li> </ul> <p>You are encouraged to share the link to the form with NBIS trainers: the goal is to find the set of evaluation questions that we think is useful enough to ask to all our course participants.</p> <p>Thanks and cheers, Richel</p> <p>From February to May 2025, both Bilderbeek and Wibberg reached out to their networks.</p> <p>On 2025-11-13, Bilderbeek presented a poster on this research at a pedagogy conference.</p> Where can I find that poster? <p>The poster can be found at <code>https://github.com/richelbilderbeek/poster_teaching_conference_20251113</code></p> <p>In January 2026, Bilderbeek converted the suggestions to unique questions to assess course quality.</p> <p>On 2026-01-15, Bilderbeek asked Wibberg for feedback</p>"},{"location":"results_4/","title":"Results 4","text":""},{"location":"results_4/#44-results-of-rq4-how-different-are-the-newly-suggested-questions-from-the-current-ones","title":"4.4. Results of RQ4: How different are the newly suggested questions from the current ones?","text":"<pre><code>No results yes\n</code></pre>"},{"location":"meeting_notes/20250306/","title":"2025-03-06 Meeting Daniel Wibberg","text":"<p>Goal: find out if and to what extent we collaborate on the 'ELIXIR evaluation evaluation' paper</p> <ul> <li>Questions about this draft?</li> <li>Join as author?</li> <li> <p>Join experiment?</p> </li> <li> <p>May I quote you on this, from the Q&amp;A document of last clinic (at <code>[URL]</code>)?   If yes, how:</p> <ul> <li>[x] 'Daniel Wibberg, co-author of [the 2020 paper] and a trainer   using this evaluation (personal communication)'</li> </ul> </li> </ul> <pre><code>Honestly, I haven't found the ELIXIR questions particularly useful\nin improving my course.\nWhile they do serve the purpose of collecting numbers for KPIs,\nthey don't provide the in-depth, qualitative feedback needed\nto make substantial course improvements.\nThe questions focus more on statistical outputs\nrather than offering insights into student experiences\nor areas for pedagogical enhancement.\nAs a result, they fall short in helping to identify specific aspects\nof the course that could benefit from revision or innovation.\n</code></pre> <ul> <li>May I quote you on this, from the Q&amp;A document of last clicic (at <code>[URL]</code>)?   If yes, how:<ul> <li>'Daniel Wibberg, co-author of [the 2020 paper] (personal communication)'</li> <li>'A co-author of [the 2020 paper] (personal communication)'</li> <li>'Someone involved in [the 2020 paper] (personal communication)'</li> <li>'Anonymous source (personal communication)'</li> </ul> </li> </ul> <pre><code>[text]\n</code></pre> <p>To do:</p> <ul> <li>RB: add that we may add responses too, if there are already 10+ responses</li> <li>RB: Make the tone more optimistic</li> <li>DW: Contact Kim Guruwitz</li> <li>DW + RB: Find a survey expert</li> <li>Get more people filling in:<ul> <li>DW: deNBI (20)</li> <li>DW: bioinformatics.de (1000)</li> <li>DW: ELIXIR training platform Slack</li> <li>DW: Training platform meeting end of March ~30</li> <li>DW: TRIANGLE ~10</li> </ul> </li> <li>Title: Improving the ELIXIR evaluation for both management and trainers</li> <li>DW: dwibberg</li> </ul> <p>Schedule:</p> <ul> <li>April 6th: check again, remind if needed</li> <li>May 6th: check results,</li> <li>&lt;10 responses at Sep 1 we abort</li> </ul> <p>Next meeting:</p> <p>Friday April 11th 13:00-(max)14:00, BW will send invite</p>"},{"location":"meeting_notes/20250411/","title":"2025-04-11 Meeting Daniel Wibberg","text":"<p>Goal: Progress</p> <ul> <li>Questions about this draft?</li> <li>Join as author?</li> <li>Join experiment?</li> </ul> <p>To do:</p> <ul> <li>[ ] RB: Add quote</li> <li>[X] RB: add that we may add responses too, if there are already 10+ responses</li> <li>[ ] DW: Contact Kim Guruwitz</li> <li>[ ] DW + RB: Find a survey expert</li> <li>Get more people filling in:<ul> <li>Status: 2 responses</li> <li>DW: deNBI (20)</li> <li>DW: bioinformatics.de (1000)</li> <li>DW: ELIXIR training platform Slack</li> <li>DW: Training platform meeting end of March ~30</li> <li>DW: TRIANGLE ~10</li> </ul> </li> <li>[x] Title: Improving the ELIXIR evaluation for both management and trainers</li> <li>[x] RB: Make the tone more optimistic</li> <li>[x] RB: add <code>dwibberg</code> as collaborator<ul> <li>[ ] DW: accept GitHub invite to be a collaborator</li> </ul> </li> </ul> <p>Schedule:</p> <ul> <li>April 6th: check again, remind if needed: 2 responses</li> <li>May 6th: check results,</li> <li>&lt;10 responses at Sep 1 we abort</li> </ul> <p>Next meeting:</p> <p>Friday April 11th 13:00-(max)14:00, BW will send invite</p>"},{"location":"papers/","title":"Papers","text":"<p>Here one can download the legally redistributable papers used in the research.</p> Reference PDF <code>[Jordan et al., 2018]</code> jordan_et_al_2018.pdf"},{"location":"papers/#references","title":"References","text":"<ul> <li><code>[Jordan et al., 2018]</code>   Jordan, Kari, Fran\u00e7ois Michonneau, and Belinda Weaver.   \"Analysis of Software and Data Carpentry\u2019s pre-and post-workshop surveys.\"   Software Carpentry. Retrieved April 13 (2018): 2023.   PDF</li> </ul>"},{"location":"presentations/","title":"Presentations","text":"<p>Here are the presentations for this paper.</p> Step Downloads 1 step_1.odp, step_1.pdf, YouTube video"}]}