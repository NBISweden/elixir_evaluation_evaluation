# Methods

## RQ1: What is the history of the ELIXIR evaluation questions?

A literature search is performed to find out the history
of the current ELIXIR evaluation questions,
with a focus on answering the following sub-questions:

- How were these evaluation questions developed?
- By which criteria where the best questions selected?

The results can be found at [RQ1 results](results_1.md).

## RQ2: Can the current ELIXIR evaluation questions be criticized?

A literature search is performed to assess the usefulness of the questions
in the ELIXIR SFT.

The results can be found at [RQ2 results](results_2.md).

<!-- markdownlint-disable MD013 --><!-- Headings cannot be split up over lines, hence will break 80 characters per line -->

## RQ3: Which ELIXIR evaluation questions are concluded from a fully transparent process?

<!-- markdownlint-enable MD013 -->

The procedure is as follows:

- At an NBIS Training Liaison meeting, introduce this procedure to the people
  involved in training, as well as advertise in the relevant communication
- Collect all questions that teachers think are useful anonymously,
  creating `Data Set 1`
- Combine `Data Set 1` with the current NBIS questions. Mix these questions
  randomly. Per question, as the teachers anonymously for reasons why
  they would be for or against each question.
  The collection of reasonings per questions results in `Data Set 2`
- Per question, and its pros and cons, vote anonymously if the question
  is useful enough to be included in a survey. Allow 'no', 'yes' and neutral

The end product is the set of questions that had more 'yes' than 'no' votes:
these are the questions that this NBIS community thinks are useful.

The results can be found at [RQ3 results](results_3.md).

## RQ4: How different are the newly suggested questions from the current ones?

The results can be found at [RQ4 results](results_4.md).
